{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f833e8cf-3559-4cf7-98ee-679a54f4ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import importlib\n",
    "from pprint import pprint\n",
    "\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import src.preprocess\n",
    "from src import dataset\n",
    "\n",
    "import src.spectrogram\n",
    "\n",
    "importlib.reload(src.preprocess)\n",
    "importlib.reload(dataset) \n",
    "importlib.reload(src.spectrogram)\n",
    "\n",
    "DATA_ROOT = \"gs://bird-clef-kimmo/data\"\n",
    "TRAIN_SHORT_AUDIO_DATA = f\"{DATA_ROOT}/train_short_audio\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "SR = 32000\n",
    "SPLIT_SECS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37971931-5f80-4559-9df9-ce273d49ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls $DATA_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03a9ae-3f90-4633-9a9d-27d8536bbca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_audio_metadata_ds = src.dataset.short_audio_metadata_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1434a16-e3c8-42ca-bf3c-c67eb252f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in short_audio_metadata_ds.take(1):\n",
    "    pprint(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da74abe-79d5-4384-a801-cd298136a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = src.dataset.read_classes()\n",
    "print(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2416b870-b5bd-4726-b43e-5f39f25400ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(url) -> tf.Tensor:\n",
    "    logging.debug(f\"Reading file: {url}\")\n",
    "    return tf.squeeze(tfio.audio.AudioIOTensor(url).to_tensor(), axis=1)  # remove channel axis\n",
    "\n",
    "def add_audio(row):\n",
    "    filename = row[\"filename\"]\n",
    "    primary_label = row[\"primary_label\"]\n",
    "    file_url = TRAIN_SHORT_AUDIO_DATA + \"/\" + primary_label + \"/\" + filename\n",
    "    [audio,] = tf.py_function(read_file, [file_url], [tf.float32])\n",
    "    return {**row, \"file_url\": file_url, \"audio\": audio}\n",
    "\n",
    "for row in short_audio_metadata_ds.map(add_audio).take(1):\n",
    "    pprint(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad760cf-2298-4c86-8c51-8bd89acec1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 3\n",
    "cols = 3\n",
    "n = rows * cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 12))\n",
    "\n",
    "for i, sample in enumerate(short_audio_metadata_ds.map(add_audio).take(n)):\n",
    "    r = i // cols\n",
    "    c = i % cols\n",
    "    ax = axes[r][c]\n",
    "    audio = sample[\"audio\"].numpy()\n",
    "    label = sample[\"scientific_name\"].numpy().decode()\n",
    "    ax.plot(np.arange(len(audio)) / SR, audio)\n",
    "    ax.set_yticks(np.arange(-1.2, 1.2, 0.2))\n",
    "    # label = label.numpy().decode('utf-8')\n",
    "    ax.set_title(label)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "Audio(audio, rate=SR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac74873-f10f-49cc-84c8-311df09ea405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio(audio):\n",
    "    length = audio.shape[-1]\n",
    "    \n",
    "    n_splits = length // (SR * SPLIT_SECS)\n",
    "        \n",
    "    splits = []\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        start = i * SR*SPLIT_SECS\n",
    "        end = (i+1) * SR*SPLIT_SECS\n",
    "        split = audio[start:end]\n",
    "        splits.append(split)\n",
    "    \n",
    "    return tf.convert_to_tensor(splits)\n",
    "\n",
    "def split_to_segments(rows):\n",
    "    audio = rows[\"audio\"]\n",
    "    \n",
    "    splits = tf.py_function(split_audio, [audio], tf.float32)\n",
    "    \n",
    "    original = tf.data.Dataset.from_tensors(rows).repeat()\n",
    "    splits_ = tf.data.Dataset.from_tensor_slices({\"segment\": splits})\n",
    "    \n",
    "    def combine_keys(a, b):\n",
    "        return {**a, **b}\n",
    "    \n",
    "    zipped = tf.data.Dataset.zip((original, splits_)).map(combine_keys)\n",
    "    return zipped\n",
    "\n",
    "def add_label(sample):\n",
    "    label = src.dataset.primary_label_to_tensor(sample[\"primary_label\"], CLASSES)\n",
    "    return sample, label\n",
    "\n",
    "def drop_keys(*keys):\n",
    "    \n",
    "    def drop(rows):\n",
    "        rows = rows.copy()\n",
    "        for key in keys:\n",
    "            rows.pop(key)\n",
    "        return rows\n",
    "\n",
    "    return drop\n",
    "\n",
    "short_audio_ds = short_audio_metadata_ds.map(add_audio).flat_map(split_to_segments).map(drop_keys(\"filename\")).map(add_label)\n",
    "\n",
    "for sample, label in short_audio_ds.take(3):\n",
    "    pprint(sample)\n",
    "    pprint(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e9a769-274c-4cb5-ab8e-f41c8586e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Mel spectrogram calculation in reference notebook\n",
    "# https://www.kaggle.com/stefankahl/birdclef2021-model-training\n",
    "RANDOM_SEED = 1337\n",
    "SAMPLE_RATE = 32000\n",
    "SIGNAL_LENGTH = 5 # seconds\n",
    "SPEC_SHAPE = (48, 128) # height x width\n",
    "FMIN = 500\n",
    "FMAX = 12500\n",
    "MAX_AUDIO_FILES = 1500\n",
    "\n",
    "hop_length = int(SIGNAL_LENGTH * SAMPLE_RATE / (SPEC_SHAPE[1] - 1))\n",
    "mel_spec = librosa.feature.melspectrogram(y=chunk, \n",
    "                                          sr=SAMPLE_RATE, \n",
    "                                          n_fft=1024, \n",
    "                                          hop_length=hop_length, \n",
    "                                          n_mels=SPEC_SHAPE[0], \n",
    "                                          fmin=FMIN, \n",
    "                                          fmax=FMAX)\n",
    "                                                \n",
    "\"\"\"\n",
    "\n",
    "SPEC_SHAPE = (48, 128)\n",
    "FMIN = 500\n",
    "FMAX = 12500\n",
    "\n",
    "def make_spectrogram_numpy(audio):\n",
    "    hop_length = int(SPLIT_SECS * SR / (SPEC_SHAPE[1] - 1))\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio.numpy(), \n",
    "                                              sr=SR, \n",
    "                                              n_fft=1024, \n",
    "                                              hop_length=hop_length, \n",
    "                                              n_mels=SPEC_SHAPE[0], \n",
    "                                              fmin=FMIN, \n",
    "                                              fmax=FMAX)\n",
    "    \n",
    "    mel_spec = librosa.power_to_db(mel_spec, ref=np.max) \n",
    "        \n",
    "    # Normalize\n",
    "    mel_spec -= mel_spec.min()\n",
    "    mel_spec /= mel_spec.max()\n",
    "    return mel_spec\n",
    "\n",
    "def add_spectrograms(sample, label):\n",
    "    tensor = sample[\"segment\"]\n",
    "    \n",
    "    # hop_length = int(SPLIT_SECS * SR / (SPEC_SHAPE[1] - 1))\n",
    "    \n",
    "    spectrogram = tfio.audio.spectrogram(\n",
    "        tensor, nfft=512, window=512, stride=256\n",
    "    )\n",
    "\n",
    "    mel_spectrogram = tfio.audio.melscale(\n",
    "        spectrogram, rate=SR, mels=SPEC_SHAPE[0], fmin=FMIN, fmax=FMAX\n",
    "    )\n",
    "\n",
    "    dbscale_mel_spectrogram = tfio.audio.dbscale(\n",
    "        mel_spectrogram, top_db=80\n",
    "    )\n",
    "    \n",
    "    sample[\"spectrogram\"] = tf.transpose(spectrogram)\n",
    "    sample[\"mel_spectrogram\"] = tf.transpose(mel_spectrogram)\n",
    "    sample[\"dbscale_mel_spectrogram\"] = tf.transpose(dbscale_mel_spectrogram)\n",
    "    \n",
    "    [mel_spec, ] = tf.py_function(make_spectrogram_numpy, [tensor], [tf.float32])\n",
    "    sample[\"mel_spec\"] = mel_spec\n",
    "\n",
    "    return sample, label\n",
    "\n",
    "def add_spectrogram(sample, label):\n",
    "    \n",
    "    sample[\"mel_spec\"] = src.spectrogram.compute_mel_spectrogram(sample[\"segment\"])\n",
    "    \n",
    "    return sample, label\n",
    "\n",
    "spectrogram_ds = short_audio_ds.map(add_spectrogram)\n",
    "\n",
    "rows = 3\n",
    "cols = 2\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(16, 12))\n",
    "                    \n",
    "for r, (sample, _) in enumerate(spectrogram_ds.take(3)):\n",
    "    axes[r][0].plot(sample[\"segment\"].numpy())\n",
    "    axes[r][1].imshow(sample[\"mel_spec\"].numpy().T)\n",
    "    axes[r][0].set(title=sample[\"primary_label\"].numpy().decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a79387-9006-4f5b-ad8a-1eed965d0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "for i, (sample, label) in enumerate(spectrogram_ds.take(12)):\n",
    "    spec = sample[\"mel_spec\"].numpy()\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    label_index = np.argmax(label.numpy())\n",
    "    clazz = src.dataset.tensor_to_class(label, CLASSES)\n",
    "    plt.title(clazz)\n",
    "    plt.imshow(spec.T, origin='lower')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "tf2-gpu.2-6.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
