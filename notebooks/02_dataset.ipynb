{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f833e8cf-3559-4cf7-98ee-679a54f4ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import logging\n",
    "import importlib\n",
    "import src.preprocess\n",
    "import pandas as pd\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "importlib.reload(src.preprocess)\n",
    "\n",
    "GS_DATA = \"gs://bird-clef-kimmo/data\"\n",
    "TRAIN_SHORT_AUDIO_DATA = f\"{GS_DATA}/train_short_audio\"\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "SR = 32000\n",
    "SPLIT_SECS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37971931-5f80-4559-9df9-ce273d49ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls $GS_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc6a6d9-2c43-4357-905b-166de0a4c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_METADATA_CSV = f\"{GS_DATA}/train_metadata.csv\"\n",
    "# TRAIN_METADATA_CSV = f\"../data/train_metadata_small.csv\"\n",
    "\n",
    "COLUMNS = [\"primary_label\",\"secondary_labels\",\"type\",\"latitude\",\"longitude\",\"scientific_name\",\"common_name\",\"date\",\"filename\",\"rating\",\"time\"]\n",
    "train_metadata_ds = tf.data.experimental.make_csv_dataset(\n",
    "    TRAIN_METADATA_CSV, batch_size=1, select_columns=COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2416b870-b5bd-4726-b43e-5f39f25400ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(url):\n",
    "    logging.debug(f\"Reading file: {url}\")\n",
    "    return tf.squeeze(tfio.audio.AudioIOTensor(url).to_tensor())\n",
    "\n",
    "def add_audio(row):\n",
    "    filename = row[\"filename\"]\n",
    "    primary_label = row[\"primary_label\"]\n",
    "    file_url = TRAIN_SHORT_AUDIO_DATA + \"/\" + primary_label + \"/\" + filename # tf.py_function(lambda filenames: [f\"{GS_DATA}/{filename}\" for filename in filenames], [filename], [tf.string])\n",
    "    audio = tf.py_function(read_file, [tf.squeeze(file_url)], [tf.float32])\n",
    "    return {**row, \"file_url\": file_url, \"audio\": audio}\n",
    "\n",
    "for row in train_metadata_ds.map(add_audio).take(4):\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac74873-f10f-49cc-84c8-311df09ea405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio(audio):\n",
    "    length = audio.shape[-1]\n",
    "    assert audio.shape[0] == 1\n",
    "    \n",
    "    audio = tf.squeeze(audio, axis=0)\n",
    "    # print(\"Shape\", audio.shape)\n",
    "    \n",
    "    # print(f\"Splitting signal of shape: {audio.shape}\")\n",
    "    \n",
    "    n_splits = length // (SR * SPLIT_SECS)\n",
    "    \n",
    "    # print(f\"Splitting to {n_splits} splits\")\n",
    "    \n",
    "    splits = []\n",
    "    \n",
    "    for i in range(n_splits):\n",
    "        start = i * SR*SPLIT_SECS\n",
    "        end = (i+1) * SR*SPLIT_SECS\n",
    "        split = audio[start:end]\n",
    "        splits.append(split)\n",
    "    \n",
    "    return tf.convert_to_tensor(splits)\n",
    "\n",
    "def split_to_segments(rows):\n",
    "    audio = rows[\"audio\"]\n",
    "    \n",
    "    splits = tf.py_function(split_audio, [audio], tf.float32)\n",
    "    \n",
    "    original = tf.data.Dataset.from_tensors(rows).repeat()\n",
    "    splits_ = tf.data.Dataset.from_tensor_slices({\"segment\": splits})\n",
    "    \n",
    "    def combine_keys(a, b):\n",
    "        return {**a, **b}\n",
    "    \n",
    "    zipped = tf.data.Dataset.zip((original, splits_)).map(combine_keys)\n",
    "    return zipped\n",
    "    # return tf.data.Dataset.from_tensor_slices(splits)\n",
    "    \n",
    "\n",
    "def drop_extra_keys(rows):\n",
    "    KEYS_TO_DROP = (\"audio\", \"filename\")\n",
    "    rows = rows.copy()\n",
    "    for key in KEYS_TO_DROP:\n",
    "        rows.pop(key)\n",
    "    return rows\n",
    "\n",
    "dataset = train_metadata_ds.map(add_audio).flat_map(split_to_segments).map(drop_extra_keys)\n",
    "\n",
    "for row in dataset.take(15):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383c67b1-05f1-4f25-b816-95408c33ec6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "tf2-gpu.2-6.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
