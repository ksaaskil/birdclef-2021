{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f833e8cf-3559-4cf7-98ee-679a54f4ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import importlib\n",
    "from pprint import pprint\n",
    "\n",
    "from IPython.display import Audio\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow_io as tfio\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import src.preprocess\n",
    "import src.dataset\n",
    "import src.spectrogram\n",
    "\n",
    "importlib.reload(src.preprocess)\n",
    "importlib.reload(src.dataset) \n",
    "importlib.reload(src.spectrogram)\n",
    "\n",
    "DATA_ROOT = \"gs://bird-clef-kimmo/data\"\n",
    "TRAIN_SHORT_AUDIO_DATA = f\"{DATA_ROOT}/train_short_audio\"\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "SR = 32000\n",
    "SPLIT_SECS = 5\n",
    "\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37971931-5f80-4559-9df9-ce273d49ac48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls $DATA_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32aede8-04f9-4792-912d-f39428115f62",
   "metadata": {},
   "source": [
    "### Metadata dataset read from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03a9ae-3f90-4633-9a9d-27d8536bbca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_audio_metadata_ds = src.dataset.short_audio_metadata_ds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1434a16-e3c8-42ca-bf3c-c67eb252f577",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in short_audio_metadata_ds.take(1):\n",
    "    pprint(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da74abe-79d5-4384-a801-cd298136a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = src.dataset.read_classes()\n",
    "print(CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2416b870-b5bd-4726-b43e-5f39f25400ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in short_audio_metadata_ds.map(src.dataset.add_audio).take(1):\n",
    "    pprint(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad760cf-2298-4c86-8c51-8bd89acec1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 3\n",
    "cols = 3\n",
    "n = rows * cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 12))\n",
    "\n",
    "for i, sample in enumerate(short_audio_metadata_ds.map(src.dataset.add_audio).take(n)):\n",
    "    r = i // cols\n",
    "    c = i % cols\n",
    "    ax = axes[r][c]\n",
    "    audio = sample[\"audio\"].numpy()\n",
    "    label = sample[\"scientific_name\"].numpy().decode()\n",
    "    ax.plot(np.arange(len(audio)) / SR, audio)\n",
    "    ax.set_yticks(np.arange(-1.2, 1.2, 0.2))\n",
    "    # label = label.numpy().decode('utf-8')\n",
    "    ax.set_title(label)\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "Audio(audio, rate=SR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d26b8a0-1a92-4123-94a8-faf93c15997c",
   "metadata": {},
   "source": [
    "### Full audio Dataset split to segments with audio and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac74873-f10f-49cc-84c8-311df09ea405",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(src.dataset)\n",
    "short_audio_ds = src.dataset.short_audio_ds()\n",
    "\n",
    "for sample, label in short_audio_ds.take(3):\n",
    "    pprint(sample)\n",
    "    pprint(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e9a769-274c-4cb5-ab8e-f41c8586e2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Mel spectrogram calculation in reference notebook\n",
    "# https://www.kaggle.com/stefankahl/birdclef2021-model-training\n",
    "RANDOM_SEED = 1337\n",
    "SAMPLE_RATE = 32000\n",
    "SIGNAL_LENGTH = 5 # seconds\n",
    "SPEC_SHAPE = (48, 128) # height x width\n",
    "FMIN = 500\n",
    "FMAX = 12500\n",
    "MAX_AUDIO_FILES = 1500\n",
    "\n",
    "hop_length = int(SIGNAL_LENGTH * SAMPLE_RATE / (SPEC_SHAPE[1] - 1))\n",
    "mel_spec = librosa.feature.melspectrogram(y=chunk, \n",
    "                                          sr=SAMPLE_RATE, \n",
    "                                          n_fft=1024, \n",
    "                                          hop_length=hop_length, \n",
    "                                          n_mels=SPEC_SHAPE[0], \n",
    "                                          fmin=FMIN, \n",
    "                                          fmax=FMAX)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "SPEC_SHAPE = (48, 128)\n",
    "FMIN = 500\n",
    "FMAX = 12500\n",
    "\n",
    "def make_spectrogram_numpy(audio):\n",
    "    hop_length = int(SPLIT_SECS * SR / (SPEC_SHAPE[1] - 1))\n",
    "    mel_spec = librosa.feature.melspectrogram(y=audio.numpy(), \n",
    "                                              sr=SR, \n",
    "                                              n_fft=1024, \n",
    "                                              hop_length=hop_length, \n",
    "                                              n_mels=SPEC_SHAPE[0], \n",
    "                                              fmin=FMIN, \n",
    "                                              fmax=FMAX)\n",
    "    \n",
    "    mel_spec = librosa.power_to_db(mel_spec, ref=np.max) \n",
    "        \n",
    "    # Normalize\n",
    "    mel_spec -= mel_spec.min()\n",
    "    mel_spec /= mel_spec.max()\n",
    "    return mel_spec\n",
    "\n",
    "def add_spectrograms(sample, label):\n",
    "    tensor = sample[\"segment\"]\n",
    "    \n",
    "    # hop_length = int(SPLIT_SECS * SR / (SPEC_SHAPE[1] - 1))\n",
    "    \n",
    "    spectrogram = tfio.audio.spectrogram(\n",
    "        tensor, nfft=512, window=512, stride=256\n",
    "    )\n",
    "\n",
    "    mel_spectrogram = tfio.audio.melscale(\n",
    "        spectrogram, rate=SR, mels=SPEC_SHAPE[0], fmin=FMIN, fmax=FMAX\n",
    "    )\n",
    "\n",
    "    dbscale_mel_spectrogram = tfio.audio.dbscale(\n",
    "        mel_spectrogram, top_db=80\n",
    "    )\n",
    "    \n",
    "    sample[\"spectrogram\"] = tf.transpose(spectrogram)\n",
    "    sample[\"mel_spectrogram\"] = tf.transpose(mel_spectrogram)\n",
    "    sample[\"dbscale_mel_spectrogram\"] = tf.transpose(dbscale_mel_spectrogram)\n",
    "    \n",
    "    [mel_spec, ] = tf.py_function(make_spectrogram_numpy, [tensor], [tf.float32])\n",
    "    sample[\"mel_spec\"] = mel_spec\n",
    "\n",
    "    return sample, label\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "rows = 3\n",
    "cols = 2\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(16, 12))\n",
    "                    \n",
    "for r, (sample, _) in enumerate(short_audio_ds.take(3)):\n",
    "    axes[r][0].plot(sample[\"segment\"].numpy())\n",
    "    axes[r][1].imshow(sample[\"mel_spec\"].numpy().T)\n",
    "    axes[r][0].set(title=sample[\"primary_label\"].numpy().decode())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a79387-9006-4f5b-ad8a-1eed965d0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "\n",
    "for i, (sample, label) in enumerate(short_audio_ds.take(12)):\n",
    "    spec = sample[\"mel_spec\"].numpy()\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    label_index = np.argmax(label.numpy())\n",
    "    clazz = src.dataset.tensor_to_class(label, CLASSES)\n",
    "    plt.title(clazz)\n",
    "    plt.imshow(spec.T, origin='lower')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83972af-72d7-4ddd-a562-04427ff40d15",
   "metadata": {},
   "source": [
    "### Bar plot of folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b34622a-b9d4-4cee-8748-ce9a5ccdd494",
   "metadata": {},
   "source": [
    "TODO: Figure out how to compute the number of elements in each fold, flat_map makes infinite datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ebb160-0e08-424e-9fd1-456fbb1520f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.data.experimental.cardinality(short_audio_metadata_ds).numpy()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "tf2-gpu.2-6.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
